--------------------------------------------------------------------------------
IDEEN & VERBESSERUNGEN
--------------------------------------------------------------------------------

Doku Windows:
 C:\> lodctr /s:c:\counter.txt
 ==> Holt aus der Registry die Namen und Beschreibungen der
 ganzen Performancecounter :-)

Die Option -d verwendet --cache nicht.

Anstelle der Pipe direkt checkresults-Dateien schreiben

check_mk -C soll Liste von Hosts bekommen können.

Bei Hosts, die kein keine Services haben, eine andere
Host-Schablone nehmen, die den Hostcheck nur on-demand ausführt.

Multisite: ein Filter für Hosts, der dann zuschlägt, wenn ein Host
einen bestimmten Service hat (geht das auch mit Substrings?)

Windows-Agent: Speicherberechung von Swap anpassen und Check mem entsprechend
anpassen, dass er TotalPage und UsedPage verwendet. Im Quellcode ist das schon
drin, der Check muss angepasst werden und auch die Schablone. Evtl. macht
man einen eigenen Check. Oder man löst es über das Check-Item.

check_mk --restore: Löscht er cache und counters? Er sollte nur die
Inhalte löschen. Es könnte nämlich sein, dass es sich nicht um Verzeichnisse,
sondern um Symlinks handelt.

check_mk --uninstall backup.tar.gz: Deinstalliert alle Dateien, die
setup installiert hat. Dazu verwendet man einfach die Pfade, die setup.sh
gespeichert hat (reicht das?). Man wird dabei gezwungen, vorher ein
Backup durchzuführen.

Livestatus-Limit-Header könnte auch einen Bereich erlauben, z.B.:
Limit: 1000 2000 (holt die zweiten Tausend Eintraege...)

Windows: Der Agent sollte die Logmeldungen nach UTF-8 konvertieren. 
Nur wie?

Logwatch: Hier sollte man wirklich einen Teil der Meldung ausgeben.
Kann man evtl. den long_service_output verwenden?

Performance counter: Generell sollten *alle* Counter von Check_MK
behandelt werden mit get_counter und *nicht* als counter in die
RRDs geschrieben, sondern bereits als Rate. Dadurch muss man alle
Graphen einmal wegwerfen. Das ist blöd. Vorteil allerdings: (1)
man kann Perf-O-Meter machen, (2) die Counter-Wrap-Erkennung
verhindert, dass in den RRDs nach einem Reboot utopische Werte
stehen (z.B. für die Kernel counter). (3) Da in den Performancedaten
bereits eine Rate steht, können auch Tools wie NagVis dafür eine
Visualisierung machen.

Multisite: Perf-O-Meter für weitere Checks einbauen.

Logfileansicht: Filter zum Suchen nach Texten.

View editor: Wenn man keine Display columns ausgewaehlt
hat, dann sollte eine Fehlermeldung kommen.

Windows services: Konfiguration von Namen für die Services
über 
  windows_service_aliasses = {
     'ACDSee Lizenzserver' : 'ProductCommunicationService',
  }
Der Schlüssel ist dabei der logische Name. Oder man macht es
umgekert. Verfahren: Als item wird der logische Alias-name
speichert. So taucht dieser dann in der Service-Description
auf. Beim Check kommt der logische Name rein. Mit dem dict
kann ich daraus den physischen berechnen und so die richtige
Zeile finden. Oder ich kann umgekehrt jede Zeile im dict
zum Physischen namen den Alias nachschlagen und so zu Zuordnung
machen.

Livestatus: Bei den Tabellen hosts und services fehlt die
Spalte 'contact_groups'. Man bekommt zwar die Einzelkontakte,
aber nicht die Gruppen. Bei den Nagios-Datenstrukturen gibt
es aber einen passenden Zeiger dafür. Sollte also nicht schwer
sein, das umzusetzen.

Checkboxen: Bei einer View macht man oben einen kleinen Reiter, der eine
Checkbox symbolisiert. Wenn man den anklickt, wir bei jedem Datensatz
zusätzlich eine Checkbox angezeigt. Das wird als Viewoption persistiert und
auch general als Layout-Parameter angeboten. Wenn die Checkboxen sichtbar sind,
werden Kommandos nur noch auf die Datensätze angewandt, welche mit einem
Kreuz markiert sind. Zur Steigerung des Bedienkomforts gibt es einen Knopf,
mit dem man alle Boxen markieren oder leeren kann (evtl. kann man das auch
darüber regeln, dass der Reiter oben nicht zwei, sondern drei Zustände
hat: Checkboxen aus, Checkboxen alle gecheckt, Checkboxen alle leer).
Damit die Checkboxen funktionieren, muss jeder Datensatz eine eindeutige ID
erzeugen können. Dazu gibt es bei jeder Datasource die Information, welche
Spalten das sind. Aktuell gibt es dazu schon "keys". Problem hier ist nur,
dass da noch die Downtime-IDs mitkommen, die man hier nicht braucht. Diese
sollte man irgendwie weglassen können.  Die Checkbox bekommt also also
HTML-Variablennamen die jeweilige ID - irgendwie enkodiert so dass es
keine Probleme mit Sonderzeichen gibt.  Wenn die Schleife der Kommandos
ausgeführt wird, muss ich jeweils noch kontrollieren, ob der Datensatz,
um den es gerade geht, auch gecheckt ist (oder Checkboxen generell aus
sind). Wenn Kein Datensatz gewählt wurde, spucke ich eine Fehlermeldung aus.

Checkboxen(2): [1] Neuer Reiter mit drei Zuständen: keine Checkboxen
alle gecheckt, alle leer. Der Zustand wird als viewoption persistent und
auch bei der View als Parameter eingebaut, so dass der Admin einen Default
vorgeben kann. Evtl. kann die View auch festlegen, ob überhaupt ein Reiter
kommt. [2] Beim Anzeigen eines Layouts muss diese eine extra TD malen,
welches eine Checkbox enthält (wenn der Reiter sichtbar ist).  Der Name der
Checkbox muss über eine eindeutige Zeilen-ID bestimmt sein.  und man muss -
nach der Tabelle - ein eine Javascript-Funktion ausgeben, die das Umschalten
der über das Tab regelt - alle an / alle aus, umschalten.  Das muss dann
per Ajax auch die View-Option umstellen und die Optik des Tabs ändern. Wenn
man auf unsichtbar schaltet, müssen alle Boxen auf gecheckt gesetzt werden,
damit das Kommando auch wirklich auf allen ausgeführt wird. [3] Wenn man
jetzt auf ein Kommando klickt, muss ich bei jedem Datensatz wieder die ID
berechnen. Dann schauen, ob es eine Check-Variable gibt. Falls ja, muss
diese auf "on" stehen, damit das Kommando ausgeführt wird.  Wenn keines
gewält ist, soll ein Hinweis kommen (gelb).

Views: Man könnte eine ASCII-View bauen, die kein HTML ausspuckt, sondern
simples ASCII. Frage ist dabei, was man mit den Paintern macht. Hier müsste
man die sichtbare Information aus den HTML-Tags rausholen, also eine Art
HTML->ASCII Filter programmieren. Auch die Überschrift ist dann betroffen
und die Fusszeile. Analog dazu könnte man sich eine Ausgabe als CSV oder
XML vorstellen. Hintergrund ist eine Art Webservice.

Precompile und Konfigerzeugung: Das könnte auf mehrere CPUs skalieren.
Dazu starten man konfigurierbar viele Threads. Bei Precompiled macht einfach
jeder der N Threads ein N'tel der Hosts. Bei der Konfigerzeugung müsste
man die Konfig zunächst im Speicher erzeugen und dann die Ergebnisse
der 8 Threads am Ende zusammenbauen. Davor muss aber die Umstellung der
Konfigerzeugung gemacht werden, bei der immer ein Host und seine Services
gemeinsam ausgespuckt werden.

Idee zur Umbenennung von Konfig-Parametern: Wenn z.B. eine Konfigvariable
hirn hieß und jetzt sepp heißen soll, dann könnte man dies Deklarieren
in check_mk.py:
renamed_config_vars = [
  ( "hirn", "depp", 1127002033 )
]
Jetzt könnte man vor dem Einlesen der Konfig die Ist-Werte speichern,
und zwar mit Objektreferenzen, um festzustellen, ob der Benutzer
hier etwas geändert hat. Alernativ schaut man nach globals:
# Nach dem Einlesen der Konfig:
for old, new, deadline in renamed_config_vars:
  if old in globals():
      sys.stderr.write("WARNING: Config var '%s' has been renamed to '%s'. Please fix this until %s" % (old, new, strftime(deadline...)))
      if time.time() < deadline:
          eval("%s = '%r'" % (new, eval(old)))
      else:
          sys.stderr.write("You had enough time to fix this. Sorry.\n")
          sys.exit(1)
Auf diese Art funktioniert erstmal alles weiter. Trotzdem wird die Variable
irgendwann planmäßig abgeschaltet.

Multisite: Wenn man bei einer View einen Filter ausfüllt (user), dann soll
irgendwo ein Icon anzeigen, dass das Resultat gefiltert ist.

Multisite: Hover: Wenn man über einen Painter geht, könnte man eine
Hover aufmachen, der einen weiteren Painter anzeigt. Das macht man
über eine Auswahlbox analog zu der "Link to".

Vorschlag von Bastian: Bei den Views könnte man den Datenbereich (Tabelle)
per Ajax refreshen und müsste nicht die ganze Seite neu aufbauen. Damit
wird ein Bildschirmflimmern vermieden.

Vorschlag(2) von Bastian: 
    Der Agent spuckt zwei neue Zeilen aus:
    StartTime: 127006756
    ..
    ..
    ..
    End Time: 127007654
    
    Check_MK prüft daraus:
    1. Ausführzeit des Agenten
    2. Alter der Daten (z.B. für asynchrone Agenten)
    
    In der main.mk muss man jetzt konfigurieren können, was
    passiert, wenn die Zeiten zu hoch sind. Z.B.:
    
    agent_execution_time_default_levels = (10, 30)
    agent_execution_time_levels = [ 
      # ORACLE-Rechner brauchen länger
      ( (30, 50), ["oracle"], ALL_HOSTS ),
    ]
    
    agent_freshness_default_levels = (5, 10)
    agent_freshness_levels = [
      ( ( 60, 90), [ "async" ], ALL_HOSTS ),
    ]
    
    Das ganze wird geprüft vom Hauptcheck. Wenn bei der
    freshness der kritische Wert zieht, werden die
    Resultate verworfen und die Checks nicht ausgeführt
    
Livestatus soll im Logfile eine Warnung ausgeben, wenn die
environment_macros aktiviert sind.

FreeBSD Agent:
  Auf der Homepage sollte ein Hinweis platziert werden, dass es einen neuen
  Agent gibt. Dieser basiert zwar auf dem Linux Agenten, gibt momentan aber
  wesentlich weniger Daten aus, da die Sektionen noch nicht portiert sind.
  
  Dazu wird eine Beschreibung benötigt, wie dieser zu installieren ist.
  1. inetd installieren
  2. /etc/services hinzufügen:
  check_mk_agent  6556/tcp   # Check_MK's agent
  3. /etc/inetd.conf hinzufügen:
  check_mk_agent  stream  tcp     nowait  root    /usr/bin/check_mk_agent check_mk_agent
  4. inetd neu starten
  -> Eventuell noch ein anderer Pfad für den Agent (?). Gibt es da andere Vorgaben
     auf FreeBSD Systemen?
  
  Die Sektionen/Checks ps und postfix_mailq sind jetzt schon kompatibel.

Idee: Bei SNMP-Checks gibt es manchmal Daten, die sich dynamisch nicht ändern
(z.B. Interfacenamen, etc.). Man könnte diese Daten cachen, so dass sie
nicht jedes mal geholt werden, sondern z.B. nur alle 10 Minuten.

IDEE: Prefetching agent: Der agent soll die Daten schon berechnen kurz bevor
sie abgefragt werden. Das ganze läuft so: Zunächst ermittelt der Agent,
wie lange die Datenberechnung im Schnitt dauert (z.B. über schleichenden
Mittelwert), sagen wir 5 Sekunden. Über den gleichen Wert ermittelt er, wie
oft er abgefragt wird, sagen wir alle 60 Sekunden. Wenn der Agent kontaktiert
wird, kann er dann einen günstigen Zeitpunkt ermitteln, zu dem er beginnt,
die Daten aufzubereiten.  Im Beispiel ist das spätestens 55 Sekunden nach
der letzten Anfrage, mit etwas Puffer kann man z.B. 5 Sekunden früher
beginnen. Das ganze schützt man über ein Lock, so dass wenn das Prefetch
noch nicht begonnen hat oder nicht fertig ist, wenn eine Anfrage kommt,
der Anfrager warten muss. Ergebnis: Auf eine Anfrage kommt im Optimalfall
immer *sofort* ein Ergebnis. Außerdem kann das Berechnen mit nice laufen.
Das könnte man auch in den Windows-Agenten integrieren und so die Probleme
beheben, die auftreten, wenn das System unter hoher Last steht.

Options --list-tags, welche alle Tags ausgibt.

Livestatus: Spalte bei Services und Hosts, die das ausgeführte Kommando
(mit expandierten Makros!) enthaelt.

Multisite: Spalte, die das Kommando (die Befehlszeile) ausgibt.

Multisite: Man soll über eine Variable die URL für die rechte Seite mitgeben
können. So kann man direkt auf eine Unterseite verlinken. Evtl. das sogar
abrufbar über ein Icon :-)

Livestatus: Informationen ueber Eskalationen ausgeben (eigene Tabelle oder
Anreicherung von contacts, hosts, services)

IPv6-Support in Check_MK:
def lookup_ipaddress(hostname):
    if fake_dns:
        return fake_dns
    elif simulation_mode:
        return "127.0.0.1"
    else:
        ipa = ipaddresses.get(hostname)
        if ipa:
            return ipa
        else:
            #return socket.gethostbyname(hostname)
            #gets only the first address of the first interface...
            for res in socket.getaddrinfo(hostname, None):
                family, socktype, proto, canonname, sockaddr = res
                return sockaddr[0]
Ausserdem kommt check_icmp damit nicht klar. Hier muss dann auf
check_ping ausgewichen werden. 

Wenn eine IP-Adresse nicht aufgelöst werden kann, sollte stattdessen eine
(konfigurierbare) Dummyadresse verwendet werden. Sonst scheitert check_mk -O,
wenn ein DNS-Eintrag verschwindet.

Livestatus: neben custom_variable_names und custom_variable_values waere
noch custom_variables huebsch, welches beides kombiniert.

Disk IO read/write: Zu einem Check zusammenfassen. Einen gemeinsamen Graphen
mit dem Windows-Check erstellen (wo ein Graph eh fehlt).

Multisite: Quicksearch evtl. case-insensitive machen?

Multisite: Für die Alerts-Stats braucht man noch die Möglichkeit,
*nach* dem Sortieren ein Limit zu setzen. Das kann auch für andere
Dinge nützlich sein. Implementierung einfach über eine view property.

Livestatus: Filter, welche auf Gruppen angewendet werden. Beispiel:
Eine Anfrage, die die Alert-Statistiken erzeugt aber nur Datensätze
ausgibt, welche mindestens ein Problem haben.
GroupFilter: col_1 > 0

Multisite: Filter, der Hosts zeigt, die entweder selbst Summary hosts sind
oder keinen haben.

Idee: Checks, die eigentlich keine Perfdaten liefern, könnten über eine
Konfiguration künstlich perfdaten bekommen, ala status=0, status=1 etc. Das
könnte man über eine Regel konfigurierbar machen: fake_perfdata = [ ... ]

Idee: Inventurcheck könnte gleich die Checkergebnisse berechnen

local-Struktur: Hier gibt es scheinbar einen Bug in mod_python.
index.py -> execfile(plugins/pages/...) -> import config
Jetzt bekommt man eine neue Instanz von config. In dem importierten
Modul kann man das wie folgt reparieren:
from mod_python import importer, apache
config = importer.import_module("config", 
    path = ["/omd/sites/webconf/share/check_mk/web/htdocs"])
Das kann aber doch keine Lösung sein. Andererseits braucht man
dies nur wenn wenn in config was ändert oder bei livestatus
(wegen der persistenten Verbindungen). Sonst kanns einem egal
sein, wenn man ein neues Modul bekommt.

Snapins: die letzten 10 Notifikationen, die letzten 10 Alerts
(evtl. umschaltbar per Tabs)

Acknowledgements: Ankreuzung, ob persistent oder nicht
Hm. Komisch. Im Code sehe ich, dass ich für persistent eine 0
setzen. Trotzdem bleibt das Acknowledgment über einen Nagios-
Neustart erhalten.

Tactical Overview: Man könnte folgendes machen: Die Kästchen
enthalten ja Links zu Views, welche die entsprechenden Probleme
anzeigen. Man könnte jetzt den Spieß umdrehen und aus den Views
die Filter-ausdrücke rausholen und diese für die Anfragen 
verwenden (und dort nur noch ein Stats: und ein Filter: has_been_ack = 0
anhängen). Somit wäre die Logik von Tactical Overview konfigurierbar.

Bei den Views z.B. im Titel die Anzahl der Antwortzeilen der Anfrage
anzeigen - Generell und bei jeder View. Bei Gruppierten Views evtl.
die Anzahl der Gruppen? Dann wüsste man die Zahl aber erst nach dem
rendern. Also geht das nicht...

if-Check: Die Bandbreiten-Erkennung klappt manchmal nicht, z.B.
weil der Provider die Bandbreite runterregelt. In den Check-Params
sollte man die tatsächliche Bandbreite angeben können.

SNMP: Hier könnte man weiter Parameter konfigurierbar machen,
z.B. snmp_parameters = []. Auf die Art kann man auch z.B. eine
alternative Portnummer angeben.
